# :pushpin: 학부 졸업프로젝트

## Video Moment Retrieval and Highlight Detection Using Captions Generated by Multimodal Large Language Models
<img src="https://github.com/user-attachments/assets/8dc48309-5bfb-42ec-8073-5fa25f88802e" alt="figure1" width="50%">

## :book: Overview  
This project aims to develop a video moment retrieval and highlight detection system leveraging captions generated by Multimodal large language models (MLLMs). By integrating advanced text-to-video alignment techniques, this system identifies key moments in videos based on textual queries.

## :wrench: Technologies Used  
- Python  
- PyTorch  
- [InternVL2-8B](https://huggingface.co/OpenGVLab/InternVL2-8B) Multimodal LLM Opensource
- Hugging Face Transformers  
- CUDA for GPU acceleration  

## :sparkles: Features  
- Efficient video moment retrieval and highlight detection using natural language queries 
- Multimodal understanding of video and text  
- Scalable architecture for large datasets  

## :file_folder: Dataset & Code 
This project uses public dataset and code for video moment retrieval and highlight detection.
- Dataset : QVHighlights dataset
- Code(baseline) : [TR-DETR](https://github.com/mingyao1120/TR-DETR)

## :chart_with_upwards_trend: Results  

The following table shows the experimental results on the QVHighlights validation set for moment retrieval and highlight detection.

| **Metric**         | **TR-DETR (Baseline)** | **Ours (Baseline + Generated Captions)** |
|---------------------|---------------------------|------------------------------------------|
| **Moment Retrieval** |                           |                                          |
| R1@0.5             | 66.97                    | 67.42                                   |
| R1@0.7             | 51.03                    | 51.94                                   |
| mAP@0.5            | 66.09                    | 66.21                                   |
| mAP@0.75           | 45.11                    | 45.74                                   |
| mAP@Avg            | 44.12                    | 45.08                                   |
| **Highlight Detection** |                       |                                          |
| mAP-VeryGood       | 40.08                    | 41.68                                   |
| HIT@1-VeryGood     | 64.58                    | 67.23                                   |

## :movie_camera: Visual Results

Below are some qualitative examples showcasing the performance of our model on video moment retrieval and highlight detection. The results demonstrate how effectively our method identifies key video moments and highlights using captions generated by multimodal large language models.
<img src="https://github.com/user-attachments/assets/5efb8fa3-521d-435c-8491-315b0c19b697" alt="figure1" width="50%">
